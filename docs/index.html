<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0" />
  <meta name="author" content="yulunliu">
  <title>Revisiting Rolling Shutter Bundle Adjustment: Toward Accurate and Fast Solution</title>

  <!-- CSS  -->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <link href="./css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection" />
  <link href="./css/style.css" type="text/css" rel="stylesheet" media="screen,projection" />
  <link href="./css/font-awesome.min.css" rel="stylesheet">

  <!--<meta property="og:image" content="http://gph.is/2oZQz8h" />-->
</head>

<body>

  <div class="navbar-fixed">

    <nav class="grey darken-4" role="navigation">
      <div class="nav-wrapper container"><a id="logo-container" href="#" class="brand-logo"></a>
        <a href="#" data-activates="nav-mobile" class="button-collapse"><i class="material-icons">menu</i></a>
        <ul class="left hide-on-med-and-down">
          <li><a class="nav-item waves-effect waves-light" href="#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#abstract">Abstract</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#paper">Paper</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#download">Download</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#results">Results</a></li>
          <!-- <li><a class="nav-item waves-effect waves-light" href="#reference">References</a></li> -->
        </ul>
      </div>
    </nav>

  </div>


  <div class="section no-pad-bot" id="index-banner">
    <div class="container scrollspy" id="home">

      <h4 class="header center black-text">Revisiting Rolling Shutter Bundle Adjustment: Toward Accurate and Fast
        Solution</h4>

      <br>

      <div class="row center">
        <h5 class="header col l3 m4 s12">
          <div class="author"><a href="https://scholar.google.com/citations?user=0z2qluIAAAAJ&hl=zh-CN" target="blank">Bangyan
              Liao<sup>1,2,*</sup></a></div>
        </h5>

        <h5 class="header col l2 m4 s12">
          <div class="author"><a href="https://delinqu.github.io/" target="blank">Delin Qu<sup>1,3,*</sup></a></div>
        </h5>

        <h5 class="header col l2 m4 s12">
          <div class="author">Yifei Xue<sup>4</sup></div>
        </h5>

        <h5 class="header col l2 m4 s12">
          <div class="author">Huiqing Zhang<sup>1</sup></div>
        </h5>

        <h5 class="header col l2 m4 s12">
          <div class="author"><a href="https://yizhenlao.github.io/" target="blank">Yizhen
              Lao<sup>1,&#8224;</span></sup></a></div>
        </h5>
      </div>

      <div class="row center affiliation-row">
        <h5 class="header col offset-l1 l2 m4 s12">
          <div class="affiliation"><a href="http://csee.hnu.edu.cn/" target="blank"><sup>1</sup>College of Computer
              Science and Electronic Engineering, Hunan University</a></div>
        </h5>

        <h5 class="header col l2 m4 s12">
          <div class="affiliation"><a href="http://eeit.hnu.edu.cn/index.htm" target="blank"><sup>2</sup>College of Electrical and
              Information Engineering, Hunan University</a></div>
        </h5>

        <h5 class="header col l3 m4 s12">
          <div class="affiliation"><a href="https://www.ucmerced.edu/" target="blank"><sup>3</sup>https://www.shlab.org.cn/</a></div>
        </h5>

        <h5 class="header col l2 m4 s12">
          <div class="affiliation"><sup>4</sup>Jiangxi Provincial Natural Resources Cause Development Center</div>
        </h5>

      </div>

    </div>
  </div>


  <div class="container">

    <div class="section">
      <!--   Icon Section   -->
      <div class="row center">
        <!-- <div class="col-sm-4"> -->
          <img class="responsive-img" src="./images/intro.png" width="75%">
        <!-- </div> -->
      </div>

    </div>

    <br>

    <div class="row section scrollspy" id="abstract">
      We propose an accurate and fast bundle adjustment (BA) solution that estimates the 6-DoF pose with an independent
      RS model of the camera and the geometry of the environment based on measurements from a rolling shutter (RS)
      camera. This tackles the challenges in the existing works, namely, relying on high frame rate video as input,
      restrictive assumptions on camera motion and poor efficiency. To this end, we first verify the positive influence
      of the image point normalization to RSBA. Then we present a novel visual residual covariance model to standardize
      the reprojection error during RSBA, which consequently improves the overall accuracy. Besides, we demonstrate the
      combination of <b>N</b>ormalization and covariance standardization <b>W</b>eighting in <b>RSBA</b>
      (<i>NW-RSBA</i>) can avoid common planar degeneracy without the need to constrain the filming manner. Finally,
      we propose an acceleration strategy for <i>NW-RSBA</i> based on the sparsity of its Jacobian matrix and Schur
      complement. The extensive synthetic and real data experiments verify the effectiveness and efficiency of the
      proposed solution over the state-of-the-art works.
    </div>


    <div class="row section scrollspy" id="paper">
      <div class="title">Paper</div>
      <br>

      <div class="row">

        <div class="center">
          <a href="https://arxiv.org/abs/2209.08503" target="_blank">
            <img src="./images/icon_pdf.png">
          </a>
          <br>
          <a href="https://arxiv.org/abs/2209.08503" target="_blank">CVPR 2023 (arXiv)</a>
        </div>

        <!-- <div class="col m6 s12 center">
          <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Liu_Single-Image_HDR_Reconstruction_CVPR_2020_supplemental.pdf"
            target="_blank">
            <img src="./images/icon_pdf.png">
          </a>
          <br>
          <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Liu_Single-Image_HDR_Reconstruction_CVPR_2020_supplemental.pdf"
            target="_blank">Supplementary Material</a>
        </div>
      </div> -->

      </div>


      <div class="row">
        <div class="subtitle">Citation</div>
        <pre>
    @InProceedings{Liao_2023_CVPR,
        author    = {Liao, Bangyan and Qu, Delin and Xue, Yifei and Zhang, Huiqing and Lao, Yizhen},
        title     = {Revisiting Rolling Shutter Bundle Adjustment: Toward Accurate and Fast Solution},
        booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
        month     = {June},
        year      = {2023}
    }
</pre>
      </div>


      <div class="section row scrollspy" id="download">
        <div class="title">Download</div>
        <div class="row">
          <!-- 
        <div class="col m3 s12 center">
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/SingleHDR_/cvpr20_singleHDR_poster_mtk.pdf"
            target="_blank">
            <img src="./images/icon_pdf.png">
          </a>
          <br>
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/SingleHDR_/cvpr20_singleHDR_poster_mtk.pdf"
            target="_blank">Poster</a>
        </div>

        <div class="col m3 s12 center">
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/SingleHDR_/cvpr20_singleHDR_video_slides_15min.pptx"
            target="_blank">
            <img src="./images/icon_pptx.png">
          </a>
          <br>
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/SingleHDR_/cvpr20_singleHDR_video_slides_15min.pptx"
            target="_blank">Slides</a>
        </div> -->

          <div class="center">
            <a href="https://github.com/DelinQu/NW-RSBA" target="_blank">
              <img src="./images/github.png">
            </a>
            <br>
            <a href="https://github.com/DelinQu/NW-RSBA" target="_blank">Code</a>
          </div>

          <!-- <div class="col m3 s12 center">
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/hdr/SingleHDR_training_data.zip" target="_blank">
            <img src="./images/icon_zip.png">
          </a>
          <br>
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/hdr/SingleHDR_training_data.zip" target="_blank">Training
            data (14 GB)</a>
        </div> -->

        </div>

        <!-- <div class="row">
        <div class="col m3 s12 center">
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/hdr/SingleHDR_results/HDR-Synth.zip" target="_blank">
            <img src="./images/icon_zip.png">
          </a>
          <br>
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/hdr/SingleHDR_results/HDR-Synth.zip"
            target="_blank">Testing data (HDR-Synth) (87 GB)</a>
        </div>

        <div class="col m3 s12 center">
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/hdr/SingleHDR_results/HDR-Real.zip" target="_blank">
            <img src="./images/icon_zip.png">
          </a>
          <br>
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/hdr/SingleHDR_results/HDR-Real.zip"
            target="_blank">Testing data (HDR-Real) (17 GB)</a>
        </div>

        <div class="col m3 s12 center">
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/hdr/SingleHDR_results/RAISE.zip" target="_blank">
            <img src="./images/icon_zip.png">
          </a>
          <br>
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/hdr/SingleHDR_results/RAISE.zip" target="_blank">Testing
            data (RAISE) (179 GB)</a>
        </div>

        <div class="col m3 s12 center">
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/hdr/SingleHDR_results/HDR-Eye.zip" target="_blank">
            <img src="./images/icon_zip.png">
          </a>
          <br>
          <a href="https://www.cmlab.csie.ntu.edu.tw/~yulunliu/hdr/SingleHDR_results/HDR-Eye.zip"
            target="_blank">Testing data (HDR-Eye) (0.52 GB)</a>
        </div>

      </div> -->

      </div>

      <div class="section row scrollspy" id="video">
        <div class="title">Video</div>
        <div class="row">
          <li><b>Coming Soon.</b></li>
          <!-- <div class="col m12 s12 center">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/UCHDhk6fciY" title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen></iframe>
          <br>
          1-minute video
        </div>
      </div> -->

        </div>


        <div class="section row scrollspy" id="results">
          <div class="title">Results</div>
          <div class="row center">
            <img class="responsive-img" src="./images/table3.png">
            <br>
            <p>Absolute trajectory error (ATE) of different RSBA methods after Sim(3) alignment to ground truth. The
              best results are shown in
              green. Since some methods will lose tracking without processing the whole sequence, thus we highlight
              the background of each cell with
              different colours depending on its corresponding DUR value. Specifically, DUR > 0.9, 0.5 < DUR ⩽ 0.9 and
                DUR ⩽ 0.5 are highlighted in light green , cyan , and orange .</p>
          </div>

          <div class="row center">
            <img class="responsive-img" src="./images/table4.png">
            <br>
            <p>Quantitative ablation study of RSSfM on TUM-RSVI [21] and WHU-RSVI [3] datasets. ATE: absolute trajectory
              error of estimated camera pose in meters (m), Runtime: time cost
              in seconds (s). Best and second best results are shown in green and blue respectively.</p>
          </div>


          <div class="row center">
            <img class="responsive-img" src="./images/fig11.png">
            <br>
            <p>Three-view graph of reconstructions using SfM pipeline with GSBA [16], NM-RSBA [2] and proposed NW-RSBA.
            </p>
          </div>

          <div class="row center">
            <img class="responsive-img" src="./images/sup2.png">
            <br>
            <p>Time cost of GSBA [4], DC-RSBA [3], NM-RSBA [1], NW-RSBA-0S (without Schur complement), NW-RSBA-1S
              (one-stage Schur
              complement to Jacobian matrices with series connection), and proposed NW-RSBA-2S (two-stage Schur
              complement to Jacobian matrices
              with parallel connection) with increasing camera number.</p>
          </div>

          <div class="row center">
            <img class="responsive-img" src="./images/sup1.png">
            <br>
            <p>Camera pose (2 nd and 3 rd columns) and reconstruction (1 st column) errors of GSBA, DC-RSBA, DM-RSBA,
              NM-RSBA and NW-
              RSBA with increasing angular and linear velocity (1 st row) and noise levels in the image (2 nd row) in
              general scenes, also with increasing
              readout directions in degeneracy scene (3 rd row).</p>
          </div>

          <div class="row center">
            <img class="responsive-img" src="./images/sup3.png">
            <br>
            <p>Ground truth and trajectories estimated by GSBA [4], NM-RSBA [1] and proposed NW-RSBA after Sim(3)
              alignment on 10
              sequences from TUM-RSVI [6] and 2 sequences from WHU-RSVI [2] datasets.</p>
          </div>
        </div>

        <!-- 
    <div class="row section scrollspy" id="reference">
      <div class="title">References</div>
      <ul>
        <li>&bull;
          <a href="https://github.com/gabrieleilertsen/hdrcnn" target="blank">HDR image reconstruction from a single
            exposure using deep CNNs</a>, SIGGRAPH Asia, 2017.
        </li>
        <li>&bull;
          <a href="http://www.cgg.cs.tsukuba.ac.jp/~endo/projects/DrTMO/" target="blank">Deep reverse tone mapping</a>,
          SIGGRAPH Asia, 2017.
        </li>
        <li>&bull;
          <a href="https://github.com/dmarnerides/hdr-expandnet" target="blank">ExpandNet: A deep convolutional neural
            network for high dynamic range expansion from low dynamic range content</a>, Eurographics, 2018.
        </li>

      </ul>
    </div> -->

      </div>

      <footer class="page-footer grey lighten-3">
        <div class="footer-copyright center black-text">
          Copyright © Bangyan Liao 2023
        </div>
      </footer>


      <!--  Scripts-->
      <script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
      <script src="js/materialize.js"></script>
      <script src="js/init.js"></script>

</body>

</html>
